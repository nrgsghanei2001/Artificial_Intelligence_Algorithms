{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hash State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(state):\n",
    "    result = []\n",
    "    for i in range(len(state)):\n",
    "        for j in range(len(state[i])):\n",
    "            if state[i][j] == \"w\":\n",
    "                result.append(0)\n",
    "            elif state[i][j] == \"d\":\n",
    "                result.append(1)\n",
    "            elif state[i][j] == \"e\":\n",
    "                result.append(2)\n",
    "\n",
    "    power = 0\n",
    "    hash_code = 0\n",
    "    for i in range(7, -1, -1):\n",
    "        hash_code += (3**power) * result[i]\n",
    "        power += 1\n",
    "\n",
    "    return hash_code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Game functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pygame\n",
    "from pygame.locals import *\n",
    "\n",
    "class QLearnAgent:\n",
    "\n",
    "    def __init__ (self, alpha, epsilon, gamma, qvalues):\n",
    "        self.alpha = alpha        # learning rate\n",
    "        self.epsilon = epsilon    # exploration rate\n",
    "        self.gamma = gamma        # discount factor\n",
    "        self.qvalues = qvalues # Q-values for each state-action pair\n",
    "        self.env = [\n",
    "            ['w', 'w', 'w', 'w', 'w', 'w', 'w', 'w', 'w', 'w', 'w'],\n",
    "            ['w', 'a', 'd', 'd', 'd', 'd', 'd', 'd', 'd', 'd', 'w'],\n",
    "            ['w', 'd', 'w', 'w', 'w', 'd', 'w', 'w', 'w', 'd', 'w'],\n",
    "            ['w', 'd', 'w', 'd', 'd', 'd', 'd', 'd', 'w', 'd', 'w'],\n",
    "            ['w', 'd', 'd', 'd', 'w', 'e', 'w', 'd', 'd', 'd', 'w'],\n",
    "            ['w', 'd', 'w', 'd', 'w', 'e', 'w', 'd', 'w', 'd', 'w'],\n",
    "            ['w', 'd', 'w', 'd', 'd', 'w', 'd', 'd', 'w', 'd', 'w'],\n",
    "            ['w', 'd', 'd', 'd', 'd', 'd', 'd', 'd', 'd', 'd', 'w'],\n",
    "            ['w', 'w', 'w', 'w', 'w', 'w', 'w', 'w', 'w', 'w', 'w'],\n",
    "            ]\n",
    "        self.num_dot = 43\n",
    "        self.actions = [0, 1, 2, 3]   # up, right, down, left\n",
    "        self.row_ind = 1\n",
    "        self.col_ind = 1\n",
    "        self.state = self.get_state(0, 3, 0, 3)\n",
    "        self.score = 0\n",
    "        self.epochs = 0\n",
    "        self.see_dot = 0\n",
    "\n",
    "    def get_state(self, start_row, end_row, start_col, end_col):\n",
    "        mat = []\n",
    "        for i in range(start_row, end_row):\n",
    "            mat_row = []\n",
    "            for j in range(start_col, end_col):\n",
    "                mat_row.append(self.env[i][j])\n",
    "            mat.append(mat_row)\n",
    "\n",
    "        return mat\n",
    "\n",
    "\n",
    "    def getAction(self):\n",
    "        \"\"\"Return the action to take in the current state.\"\"\"\n",
    "        x = random.random()\n",
    "        if x < self.epsilon or self.see_dot > 20: # explore\n",
    "            action = random.choice(self.actions)\n",
    "        else: # exploit\n",
    "            action = self.getPolicy()\n",
    "\n",
    "        return action\n",
    "\n",
    "\n",
    "    def getPolicy(self):\n",
    "        \"\"\"Return the best action to take in the current state.\"\"\"\n",
    "        # Get the Q-values for each action\n",
    "        code = encode(self.state)\n",
    "        qvalues = [ self.qvalues[code][action] for action in self.actions ]\n",
    "        ind = qvalues.index(max(qvalues))\n",
    "        # Return the action with the maximum Q-value\n",
    "        return ind\n",
    " \n",
    "    def get_next_state(self, action):\n",
    "        reward = 0\n",
    "        if action == 0:   # up\n",
    "            if self.env[self.row_ind - 1][self.col_ind] == 'w':\n",
    "                new_state = self.state\n",
    "                reward = -2\n",
    "                self.see_dot += 1\n",
    "            else:\n",
    "                if self.env[self.row_ind - 1][self.col_ind] == 'd':\n",
    "                    reward = 10\n",
    "                    self.num_dot -= 1\n",
    "                    self.see_dot = 0\n",
    "                elif self.env[self.row_ind - 1][self.col_ind] == 'e':\n",
    "                    reward = -1\n",
    "                    self.see_dot += 1\n",
    "                self.env[self.row_ind - 1][self.col_ind] = 'a'\n",
    "                self.env[self.row_ind][self.col_ind] = 'e'\n",
    "                new_state = self.get_state(self.row_ind - 2, self.row_ind + 1, self.col_ind-1, self.col_ind+2)\n",
    "                self.row_ind -= 1\n",
    "                \n",
    "        elif action == 1:   # right\n",
    "            if self.env[self.row_ind][self.col_ind+1] == 'w':\n",
    "                new_state = self.state\n",
    "                reward = -2\n",
    "                self.see_dot += 1\n",
    "            else:\n",
    "                if self.env[self.row_ind][self.col_ind+1] == 'd':\n",
    "                    reward = 10\n",
    "                    self.num_dot -= 1\n",
    "                    self.see_dot = 0\n",
    "                elif self.env[self.row_ind][self.col_ind+1] == 'e':\n",
    "                    reward = -1\n",
    "                    self.see_dot += 1\n",
    "                self.env[self.row_ind][self.col_ind+1] = 'a'\n",
    "                self.env[self.row_ind][self.col_ind] = 'e'\n",
    "                new_state = self.get_state(self.row_ind-1, self.row_ind+2, self.col_ind, self.col_ind+3)\n",
    "                self.col_ind += 1\n",
    "                \n",
    "        elif action == 2:    # down\n",
    "            if self.env[self.row_ind+1][self.col_ind] == 'w':\n",
    "                new_state = self.state\n",
    "                reward = -2\n",
    "                self.see_dot += 1\n",
    "            else:\n",
    "                if self.env[self.row_ind+1][self.col_ind] == 'd':\n",
    "                    reward = 10\n",
    "                    self.num_dot -= 1\n",
    "                    self.see_dot = 0\n",
    "                elif self.env[self.row_ind+1][self.col_ind] == 'e':\n",
    "                    reward = -1\n",
    "                    self.see_dot += 1\n",
    "                self.env[self.row_ind+1][self.col_ind] = 'a'\n",
    "                self.env[self.row_ind][self.col_ind] = 'e'\n",
    "                new_state = self.get_state(self.row_ind, self.row_ind+3, self.col_ind-1, self.col_ind+2)\n",
    "                self.row_ind += 1\n",
    "\n",
    "        elif action == 3:    # left\n",
    "            if self.env[self.row_ind][self.col_ind-1] == 'w':\n",
    "                new_state = self.state\n",
    "                reward = -2\n",
    "                self.see_dot += 1\n",
    "            else:\n",
    "                if self.env[self.row_ind][self.col_ind-1] == 'd':\n",
    "                    reward = 10\n",
    "                    self.num_dot -= 1\n",
    "                    self.see_dot = 0\n",
    "                elif self.env[self.row_ind][self.col_ind-1] == 'e':\n",
    "                    reward = -1\n",
    "                    self.see_dot += 1\n",
    "                self.env[self.row_ind][self.col_ind-1] = 'a'\n",
    "                self.env[self.row_ind][self.col_ind] = 'e'\n",
    "                new_state = self.get_state(self.row_ind-1, self.row_ind+2, self.col_ind-2, self.col_ind+1)\n",
    "                self.col_ind -= 1\n",
    "\n",
    "        self.state = new_state\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def get_value(self):\n",
    "        \"\"\"Return the maximum Q-value for the current state.\"\"\"\n",
    "\n",
    "        # Get the Q-values for each action\n",
    "        code = encode(self.state)\n",
    "        qvalues = [ self.qvalues[code][action] for action in self.actions ]\n",
    "        return(max(qvalues))\n",
    "\n",
    "    def update_qvalue(self):\n",
    "        if self.num_dot == 0:\n",
    "            self.terminal()\n",
    "            return 1\n",
    "        action = self.getAction()\n",
    "        code = encode(self.state)\n",
    "        current_qvalue = self.qvalues[code][action]\n",
    "        reward = self.get_next_state(action)\n",
    "        self.epochs += 1\n",
    "        self.score += reward\n",
    "        self.update_epsilon()\n",
    "        max_next_qvalue = self.get_value()\n",
    "\n",
    "        # Compute the new Q-value\n",
    "        new_qvalue = current_qvalue + self.alpha * (reward + self.gamma * max_next_qvalue - current_qvalue)\n",
    "        self.qvalues[code][action] = new_qvalue\n",
    "        return 0\n",
    "\n",
    "    def update_epsilon(self):\n",
    "        if self.epsilon >= 0.1:\n",
    "            self.epsilon -= 0.001 \n",
    "\n",
    "    def display (self):\n",
    "        for r in range (len(self.env)):\n",
    "            for c in range (len(self.env[r])):\n",
    "                if self.env[r][c] == 'a':\n",
    "                    print ('A', end=\" \"),\n",
    "                elif self.env[r][c] == 'd':\n",
    "                    print ('D', end=\" \"),\n",
    "                elif self.env[r][c] == 'w':\n",
    "                    print ('W', end=\" \"),\n",
    "                elif self.env[r][c] == 'e':\n",
    "                    print ('E', end=\" \"),\n",
    "            print() \n",
    "\n",
    "    def terminal(self):\n",
    "        return  \n",
    "\n",
    "    def play_game(self):\n",
    "        pygame.init()\n",
    "        cell_size = 100  \n",
    "        map_width = 11    # Number of row cells\n",
    "        map_height = 9    # Number of column cells\n",
    "        screen_width = cell_size * map_width\n",
    "        screen_height = cell_size * map_height\n",
    "        screen = pygame.display.set_mode((screen_width, screen_height))\n",
    "        pygame.display.set_caption(\"PacMan\")\n",
    "        font = pygame.font.Font(None, 34)\n",
    "        WHITE = (255, 255, 255)\n",
    "        BLACK = (0, 0, 0)\n",
    "        \n",
    "        pacman_image = pygame.image.load(\"pacman.png\")\n",
    "        pacman_image = pygame.transform.scale(pacman_image, (cell_size, cell_size))\n",
    "        dot_image = pygame.image.load(\"pellet.png\")\n",
    "        dot_image = pygame.transform.scale(dot_image, (cell_size, cell_size))\n",
    "\n",
    "        is_end = False\n",
    "        agent_i = agent_j = 0   # position of agent to display with image\n",
    "        dot_position = []     # save position of dots\n",
    "        while not is_end:\n",
    "            is_end = self.update_qvalue()\n",
    "            screen.fill(BLACK)\n",
    "            running = True\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    running = False\n",
    "            if not running:\n",
    "                break\n",
    "            \n",
    "            for x in range(map_height):\n",
    "                for y in range(map_width):\n",
    "                    rectangle = pygame.Rect(y * cell_size, x * cell_size, cell_size, cell_size)\n",
    "                    cell_color = WHITE\n",
    "                    if self.env[x][y] == \"w\":\n",
    "                        cell_color = BLACK\n",
    "                    if self.env[x][y] == \"d\":\n",
    "                        dot_position.append((y * cell_size, x * cell_size))\n",
    "                    if self.env[x][y] == \"a\":\n",
    "                        agent_i = y * cell_size\n",
    "                        agent_j = x * cell_size\n",
    "\n",
    "                    pygame.draw.rect(screen, cell_color, rectangle)\n",
    "                    \n",
    "\n",
    "            score_text = font.render(f\"Score: {self.score}\", True, WHITE)\n",
    "            screen.blit(score_text, (10, 10))\n",
    "            screen.blit(pacman_image, (agent_i, agent_j))\n",
    "            for dot in dot_position:\n",
    "                screen.blit(dot_image, (dot[0], dot[1]))\n",
    "            dot_position = []\n",
    "            pygame.display.flip()\n",
    "            pygame.time.delay(100)\n",
    "        pygame.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qvalues = np.zeros((3**8, 4))\n",
    "\n",
    "for i in range(100):\n",
    "    is_end = False\n",
    "    game = QLearnAgent(0.1, 0.9, 0.5, qvalues)\n",
    "    while not is_end:\n",
    "        is_end = game.update_qvalue()\n",
    "    qvalues = game.qvalues\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test and visualize the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = QLearnAgent(0.1, 0.9, 0.5, qvalues)\n",
    "game.play_game()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4e26ec1bab8a1abd2e5a712081492a9566af19802245f28e584dda2f9826c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
